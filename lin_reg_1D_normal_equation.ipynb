{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1224fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Project:\n",
    "#      PyTorch Dojo (https://github.com/wo3kie/ml-dojo)\n",
    "#\n",
    "# Author:\n",
    "#      Lukasz Czerwinski (https://www.lukaszczerwinski.pl/)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9c2dd",
   "metadata": {},
   "source": [
    "$$\n",
    "\n",
    "\\begin{pmatrix}\n",
    "y_0 \\\\\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}\n",
    "\n",
    "=\n",
    "\n",
    "\\begin{pmatrix}\n",
    "x_{00} & x_{01}=1 \\\\\n",
    "x_{10} & x_{11}=1 \\\\\n",
    "x_{20} & x_{21}=1 \\\\\n",
    "x_{30} & x_{31}=1 \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "x_{n0} & x_{n1}=1 \\\\\n",
    "\\end{pmatrix} \n",
    "\n",
    "\\cdot\n",
    "\n",
    "\\begin{pmatrix}\n",
    "w_0 \\\\\n",
    "w_1\n",
    "\\end{pmatrix}\n",
    "\n",
    "$$\n",
    "\n",
    "$$ Y = X \\cdot w $$\n",
    "$$ X^T \\cdot X \\cdot \\omega = X^T \\cdot Y $$\n",
    "$$ (X^T \\cdot X)^{-1} \\cdot X^T \\cdot X \\cdot \\omega = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot Y $$\n",
    "$$ \\omega = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot Y $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03184a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import arange, float32, ones_like, randn, round, stack, tensor\n",
    "\n",
    "\n",
    "def linear_regression_1d_ne(X, y):\n",
    "    \"\"\"\n",
    "    Solves linear regression in one dimension using the normal equations.\n",
    "    \"\"\"\n",
    "    \n",
    "    size = X.shape[0]\n",
    "    assert X.shape == (size, 2)\n",
    "    assert y.shape == (size, )\n",
    "\n",
    "    w = (X.T @ X).inverse() @ X.T @ y\n",
    "    assert w.shape == (2,)\n",
    "    \n",
    "    #\n",
    "    # A preferable and more numerically stable solution that internally uses SVD decomposition.\n",
    "    #\n",
    "    # https://docs.pytorch.org/docs/stable/generated/torch.linalg.lstsq.html\n",
    "    #\n",
    "    # (w, residuals, rank, singular_values) = lstsq(X, y)\n",
    "    #\n",
    "\n",
    "    slope = w[0]\n",
    "    intercept = w[1]\n",
    "\n",
    "    return (slope, intercept)\n",
    "\n",
    "\n",
    "def _test_linear_regression_1d_ne(A, B, S, M, N):\n",
    "    \"\"\"\n",
    "    Tests the linear regression normal equation solution by generating synthetic data with a known slope and intercept, \n",
    "    adding noise, and verifying that the computed slope and intercept are close to the original values.\n",
    "\n",
    "    Parameters:\n",
    "        A (float): Model's slope\n",
    "        B (float): Model's intercept\n",
    "        S (float): Samples\n",
    "        M (float): Max value of x\n",
    "        N (float): Noise level (%)\n",
    "    \"\"\"\n",
    "\n",
    "    noise = N * (M / 100.0) * randn((S, ), dtype=float32)\n",
    "    assert noise.shape == (S, )\n",
    "\n",
    "    x = arange(0, M, M/S, dtype=float32)\n",
    "    assert x.shape == (S, )\n",
    "\n",
    "    y = (A * x + B) + noise\n",
    "    assert y.shape == (S, )\n",
    "\n",
    "    X = stack((x, ones_like(x)), dim=1)\n",
    "    assert X.shape == (S, 2)\n",
    "\n",
    "    (slope, intercept) = linear_regression_1d_ne(X, y)\n",
    "    assert round(slope) == tensor(A)\n",
    "    assert round(intercept) == tensor(B)\n",
    "\n",
    "\n",
    "def test_linear_regression_1d_ne():\n",
    "    _test_linear_regression_1d_ne(A=1.0, B=1.0, S=100, M=10.0, N=0.0)\n",
    "    _test_linear_regression_1d_ne(A=2.0, B=3.0, S=100, M=10.0, N=0.0)\n",
    "    _test_linear_regression_1d_ne(A=3.0, B=6.0, S=100, M=10.0, N=0.0)\n",
    "\n",
    "    _test_linear_regression_1d_ne(A=-1.0, B=-1.0, S=100, M=10.0, N=0.0)\n",
    "    _test_linear_regression_1d_ne(A=-2.0, B=-3.0, S=100, M=10.0, N=0.0)\n",
    "    _test_linear_regression_1d_ne(A=-3.0, B=-6.0, S=100, M=10.0, N=0.0)\n",
    "\n",
    "    _test_linear_regression_1d_ne(A=1.0, B=1.0, S=100, M=10.0, N=3.0)\n",
    "    _test_linear_regression_1d_ne(A=2.0, B=3.0, S=100, M=10.0, N=6.0)\n",
    "    _test_linear_regression_1d_ne(A=3.0, B=6.0, S=100, M=10.0, N=9.0)\n",
    "\n",
    "    _test_linear_regression_1d_ne(A=-1.0, B=-1.0, S=100, M=10.0, N=3.0)\n",
    "    _test_linear_regression_1d_ne(A=-2.0, B=-3.0, S=100, M=10.0, N=6.0)\n",
    "    _test_linear_regression_1d_ne(A=-3.0, B=-6.0, S=100, M=10.0, N=9.0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_linear_regression_1d_ne()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
