{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5460cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Project:\n",
    "#      PyTorch Dojo (https://github.com/wo3kie/ml-dojo)\n",
    "#\n",
    "# Author:\n",
    "#      Lukasz Czerwinski (https://www.lukaszczerwinski.pl/)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819b7bd",
   "metadata": {},
   "source": [
    "$$ H(X, Y) = \\sum_{e \\in \\mathcal{E}} P(X=e) \\, \\log_2 \\left( \\frac{1}{P(Y=e)} \\right) $$\n",
    "$$ \\\\[2em]$$\n",
    "$$ H(X, Y) = \\text{How many bits on average, using probabilities from X, and codes from Y.} $$\n",
    "$$ \\\\[2em] $$\n",
    "$$ \\text{Example} $$\n",
    "$$ \\text{X: 8/10 \"S\", 2/10 \"RAIN\"} $$\n",
    "$$ \\text{X: \"S\", \"RAIN\", \"S\", \"S\", \"S\", \"S\", \"S\", \"RAIN\", \"S\", \"S\", ...} $$\n",
    "$$ \\\\[2em] $$\n",
    "$$ \\text{Y: 3/10 \"SUN\", 7/10 \"R\"} $$\n",
    "$$ \\text{Y: \"R\", \"SUN\", \"R\", \"R\", \"R\", \"SUN\", \"R\", \"SUN\", \"R\", \"R\", ...} $$\n",
    "$$ \\\\[2em]$$\n",
    "$$ X=\\Bigg[ sunny=\\frac{8}{10}, rainy=\\frac{2}{10} \\Bigg] $$\n",
    "$$ Y=\\Bigg[ sunny=\\frac{3}{10}, rainy=\\frac{7}{10} \\Bigg] $$\n",
    "$$ \\\\[2em]$$\n",
    "$$ H( X, Y) = P(X=\\text{sunny}) \\, \\log_2 \\Bigg( \\frac{1}{P(Y=\\text{sunny})} \\Bigg) + P(X=\\text{rainy}) \\, \\log_2 \\Bigg( \\frac{1}{P(Y=\\text{rainy})} \\Bigg) $$\n",
    "$$ crossentropy = 8/10 \\cdot \\log_2 10/3 + 2/10 \\cdot \\log_2 10/7 = 1.492 $$\n",
    "$$ entropy = H( X, X) = 8/10 \\cdot \\log_2 10/8 + 2/10 \\cdot \\log_2 10/2 = 0.722 $$\n",
    "$$ \\text{With non‑optimal coding, we use 0.770 more bits than necessary.} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import import_ipynb\n",
    "from common import assert_eq, assert_ne, T # type: ignore\n",
    "import common # type: ignore\n",
    "\n",
    "def _cross_entropy_d(dist_x, dist_y):\n",
    "    \"\"\"\n",
    "    Calculates the cross-entropy of two distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    assert_eq(isinstance(dist_x, torch.Tensor), True)\n",
    "    assert_eq(isinstance(dist_y, torch.Tensor), True)\n",
    "    assert_eq(dist_y.sum().item(), 1.0, atol=0.01)\n",
    "\n",
    "    return -(dist_x * (dist_y.clamp(1e-10)).log2()).sum().item()\n",
    "\n",
    "\n",
    "def cross_entropy(iterable_x, iterable_y, count=False, norm=False):\n",
    "    \"\"\"\n",
    "    Calculates the cross-entropy of two distributions (count=False), or vectors with samples (count=True).\n",
    "    \"\"\"\n",
    "\n",
    "    iterable_x = T(iterable_x)\n",
    "    iterable_y = T(iterable_y)\n",
    "\n",
    "    if count == True:\n",
    "        iterable_x = common.count(iterable_x)[1]\n",
    "        iterable_y = common.count(iterable_y)[1]\n",
    "\n",
    "    if (count == True) or (norm == True):\n",
    "        iterable_x = iterable_x / iterable_x.sum()\n",
    "        iterable_y = iterable_y / iterable_y.sum()\n",
    "\n",
    "    return _cross_entropy_d(iterable_x, iterable_y)\n",
    "\n",
    "\n",
    "def test_cross_entropy_1():\n",
    "    # H(X, Y) = cross-entropy(X, Y) = how many bits more, on average, using probabilities from X, and codes from Y\n",
    "    assert_eq(cross_entropy([8/10, 2/10], [3/10, 7/10]), 1.492, atol=0.01)\n",
    "    \n",
    "    # H(X) = H(X, X) = entropy(x) = optimal code lenght for X in bits\n",
    "    assert_eq(cross_entropy([8/10, 2/10], [8/10, 2/10]), 0.722, atol=0.01)\n",
    "\n",
    "\n",
    "def test_cross_entropy_2():\n",
    "    assert_eq(cross_entropy([1], [1]), 0.0, atol=0.01)\n",
    "    assert_eq(cross_entropy([1/2, 1/2], [1/2, 1/2]), 1.0, atol=0.01)\n",
    "    assert_eq(cross_entropy([1/4, 1/4, 1/4, 1/4], [1/4, 1/4, 1/4, 1/4]), 2.0, atol=0.01)\n",
    "\n",
    "    assert_eq(cross_entropy([1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], count=True), 0.000, atol=0.01)\n",
    "    assert_eq(cross_entropy([1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 0, 0], count=True), 1.207, atol=0.01)\n",
    "    assert_eq(cross_entropy([1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 1, 1, 0, 0, 0, 0], count=True), 1.000, atol=0.01)\n",
    "    assert_eq(cross_entropy([1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 0, 0, 0, 0, 0, 0], count=True), 1.207, atol=0.01)\n",
    "\n",
    "\n",
    "def test_cross_entropy_3():       \n",
    "    # \n",
    "    # Cross‑entropy, although commonly used as a loss function, is not symmetric and does not constitute a distance metric.\n",
    "    #\n",
    "    assert_ne(cross_entropy([0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1], count=True, norm=True), 0.000)\n",
    "\n",
    "    #             predicted probability of sun\n",
    "    #        predicted probability of rain    \\\n",
    "    #      actual probability of sun      \\    \\\n",
    "    # actual probability of rain    \\      \\    \\\n",
    "    #                           \\    \\      \\    \\\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.1, 0.9], norm=True), 0.468, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.2, 0.8], norm=True), 0.521, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.3, 0.7], norm=True), 0.636, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.4, 0.6], norm=True), 0.795, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.5, 0.5], norm=True), 1.000, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.6, 0.4], norm=True), 1.263, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.7, 0.3], norm=True), 1.614, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.8, 0.2], norm=True), 2.121, atol=0.01)\n",
    "    assert_eq(cross_entropy([0.1, 0.9], [0.9, 0.1], norm=True), 3.004, atol=0.01)\n",
    "\n",
    "\n",
    "    mean_squared_error = lambda x, y: ((T(x) - T(y)) ** 2).mean().item()\n",
    "\n",
    "    #                  predicted probability of sun\n",
    "    #             predicted probability of rain    \\\n",
    "    #           actual probability of sun      \\    \\\n",
    "    #      actual probability of rain    \\      \\    \\\n",
    "    #                                \\    \\      \\    \\\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.1, 0.9]), 0.000, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.2, 0.8]), 0.009, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.3, 0.7]), 0.039, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.4, 0.6]), 0.089, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.5, 0.5]), 0.159, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.6, 0.4]), 0.249, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.7, 0.3]), 0.359, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.8, 0.2]), 0.489, atol=0.01)\n",
    "    assert_eq(mean_squared_error([0.1, 0.9], [0.9, 0.1]), 0.639, atol=0.01)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_cross_entropy_1()\n",
    "    test_cross_entropy_2()\n",
    "    test_cross_entropy_3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
